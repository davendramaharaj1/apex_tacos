{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generating xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1 Preprocess CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed CSV file created: preprocessed_output.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_csv(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Processes the CSV file by mapping each of the timestep values to unique integers.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): The path to the input CSV file. //Might update with systemn\n",
    "    output_file (str): The path to the output preprocessed CSV file. //Chage this to store the csv somewhere else\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    timestep_mapping = {} # Dictionary to map each timestep to a unique integer\n",
    "    current_timestep = 0 \n",
    "    \n",
    "    with open(input_file, 'r') as file:\n",
    "        csv_reader = csv.reader(file) # Read the CSV file\n",
    "        rows = list(csv_reader) # Store the rows of the CSV in a list\n",
    "    \n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        csv_writer = csv.writer(file) # Write to the output CSV file\n",
    "\n",
    "        #Iterate through each row in the CSV file\n",
    "        for row in rows:\n",
    "            timestep = float(row[0]) # Extract the timestep value from the row\n",
    "            \n",
    "            if timestep not in timestep_mapping: # If the timestep is not already mapped\n",
    "                timestep_mapping[timestep] = current_timestep # Map the timestep to the current current_timestep equal \n",
    "                current_timestep += 1  # Increment the current_timestep\n",
    "            \n",
    "            row[0] = str(timestep_mapping[timestep]) # Update the timestep value in the row\n",
    "            csv_writer.writerow(row) \n",
    "\n",
    "# input and output CSV file paths\n",
    "input_file = 'build/bin/output.csv'\n",
    "output_file = 'preprocessed_output.csv'\n",
    "\n",
    "# Preprocess the CSV file\n",
    "preprocess_csv(input_file, output_file)\n",
    "print(f\"Preprocessed CSV file created: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.2 Create Graphs list from Preprocessed CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of     Timestep  chunkID  source  destination\n",
      "0          0        0       0            1\n",
      "1          0        0       0            3\n",
      "2          0        1       1            0\n",
      "3          0        1       1            2\n",
      "4          0        1       1            4\n",
      "5          0        2       2            1\n",
      "6          0        2       2            5\n",
      "7          0        3       3            0\n",
      "8          0        3       3            4\n",
      "9          0        3       3            6\n",
      "10         0        4       4            1\n",
      "11         0        4       4            3\n",
      "12         0        4       4            5\n",
      "13         0        4       4            7\n",
      "14         0        5       5            2\n",
      "15         0        5       5            4\n",
      "16         0        5       5            8\n",
      "17         0        6       6            3\n",
      "18         0        6       6            7\n",
      "19         0        7       7            4\n",
      "20         0        7       7            6\n",
      "21         0        7       7            8\n",
      "22         0        8       8            5\n",
      "23         0        8       8            7>\n",
      "src =  0\n",
      "dst =  1\n",
      "chunk =  0\n",
      "src =  0\n",
      "dst =  3\n",
      "chunk =  0\n",
      "src =  1\n",
      "dst =  0\n",
      "chunk =  1\n",
      "src =  1\n",
      "dst =  2\n",
      "chunk =  1\n",
      "src =  1\n",
      "dst =  4\n",
      "chunk =  1\n",
      "src =  2\n",
      "dst =  1\n",
      "chunk =  2\n",
      "src =  2\n",
      "dst =  5\n",
      "chunk =  2\n",
      "src =  3\n",
      "dst =  0\n",
      "chunk =  3\n",
      "src =  3\n",
      "dst =  4\n",
      "chunk =  3\n",
      "src =  3\n",
      "dst =  6\n",
      "chunk =  3\n",
      "src =  4\n",
      "dst =  1\n",
      "chunk =  4\n",
      "src =  4\n",
      "dst =  3\n",
      "chunk =  4\n",
      "src =  4\n",
      "dst =  5\n",
      "chunk =  4\n",
      "src =  4\n",
      "dst =  7\n",
      "chunk =  4\n",
      "src =  5\n",
      "dst =  2\n",
      "chunk =  5\n",
      "src =  5\n",
      "dst =  4\n",
      "chunk =  5\n",
      "src =  5\n",
      "dst =  8\n",
      "chunk =  5\n",
      "src =  6\n",
      "dst =  3\n",
      "chunk =  6\n",
      "src =  6\n",
      "dst =  7\n",
      "chunk =  6\n",
      "src =  7\n",
      "dst =  4\n",
      "chunk =  7\n",
      "src =  7\n",
      "dst =  6\n",
      "chunk =  7\n",
      "src =  7\n",
      "dst =  8\n",
      "chunk =  7\n",
      "src =  8\n",
      "dst =  5\n",
      "chunk =  8\n",
      "src =  8\n",
      "dst =  7\n",
      "chunk =  8\n",
      "<bound method NDFrame.head of     Timestep  chunkID  source  destination\n",
      "24         1        3       0            1\n",
      "25         1        1       0            3\n",
      "26         1        4       1            0\n",
      "27         1        4       1            2\n",
      "28         1        0       1            4\n",
      "29         1        5       2            1\n",
      "30         1        1       2            5\n",
      "31         1        6       3            0\n",
      "32         1        6       3            4\n",
      "33         1        0       3            6\n",
      "34         1        7       4            1\n",
      "35         1        7       4            3\n",
      "36         1        3       4            5\n",
      "37         1        5       4            7\n",
      "38         1        8       5            2\n",
      "39         1        8       5            4\n",
      "40         1        4       5            8\n",
      "41         1        3       6            7\n",
      "42         1        8       7            6\n",
      "43         1        6       7            8\n",
      "44         1        7       8            5>\n",
      "src =  0\n",
      "dst =  1\n",
      "chunk =  3\n",
      "src =  0\n",
      "dst =  3\n",
      "chunk =  1\n",
      "src =  1\n",
      "dst =  0\n",
      "chunk =  4\n",
      "src =  1\n",
      "dst =  2\n",
      "chunk =  4\n",
      "src =  1\n",
      "dst =  4\n",
      "chunk =  0\n",
      "src =  2\n",
      "dst =  1\n",
      "chunk =  5\n",
      "src =  2\n",
      "dst =  5\n",
      "chunk =  1\n",
      "src =  3\n",
      "dst =  0\n",
      "chunk =  6\n",
      "src =  3\n",
      "dst =  4\n",
      "chunk =  6\n",
      "src =  3\n",
      "dst =  6\n",
      "chunk =  0\n",
      "src =  4\n",
      "dst =  1\n",
      "chunk =  7\n",
      "src =  4\n",
      "dst =  3\n",
      "chunk =  7\n",
      "src =  4\n",
      "dst =  5\n",
      "chunk =  3\n",
      "src =  4\n",
      "dst =  7\n",
      "chunk =  5\n",
      "src =  5\n",
      "dst =  2\n",
      "chunk =  8\n",
      "src =  5\n",
      "dst =  4\n",
      "chunk =  8\n",
      "src =  5\n",
      "dst =  8\n",
      "chunk =  4\n",
      "src =  6\n",
      "dst =  7\n",
      "chunk =  3\n",
      "src =  7\n",
      "dst =  6\n",
      "chunk =  8\n",
      "src =  7\n",
      "dst =  8\n",
      "chunk =  6\n",
      "src =  8\n",
      "dst =  5\n",
      "chunk =  7\n",
      "<bound method NDFrame.head of     Timestep  chunkID  source  destination\n",
      "45         2        6       0            1\n",
      "46         2        2       1            0\n",
      "47         2        3       1            2\n",
      "48         2        2       1            4\n",
      "49         2        8       2            1\n",
      "50         2        7       3            0\n",
      "51         2        1       3            6\n",
      "52         2        8       4            3\n",
      "53         2        6       4            5\n",
      "54         2        0       4            7\n",
      "55         2        7       5            2\n",
      "56         2        1       5            8\n",
      "57         2        5       7            6\n",
      "58         2        3       7            8>\n",
      "src =  0\n",
      "dst =  1\n",
      "chunk =  6\n",
      "src =  1\n",
      "dst =  0\n",
      "chunk =  2\n",
      "src =  1\n",
      "dst =  2\n",
      "chunk =  3\n",
      "src =  1\n",
      "dst =  4\n",
      "chunk =  2\n",
      "src =  2\n",
      "dst =  1\n",
      "chunk =  8\n",
      "src =  3\n",
      "dst =  0\n",
      "chunk =  7\n",
      "src =  3\n",
      "dst =  6\n",
      "chunk =  1\n",
      "src =  4\n",
      "dst =  3\n",
      "chunk =  8\n",
      "src =  4\n",
      "dst =  5\n",
      "chunk =  6\n",
      "src =  4\n",
      "dst =  7\n",
      "chunk =  0\n",
      "src =  5\n",
      "dst =  2\n",
      "chunk =  7\n",
      "src =  5\n",
      "dst =  8\n",
      "chunk =  1\n",
      "src =  7\n",
      "dst =  6\n",
      "chunk =  5\n",
      "src =  7\n",
      "dst =  8\n",
      "chunk =  3\n",
      "<bound method NDFrame.head of     Timestep  chunkID  source  destination\n",
      "59         3        2       0            3\n",
      "60         3        5       1            0\n",
      "61         3        6       1            2\n",
      "62         3        8       3            0\n",
      "63         3        4       3            6\n",
      "64         3        5       4            3\n",
      "65         3        0       4            5\n",
      "66         3        2       4            7\n",
      "67         3        2       5            8\n",
      "68         3        1       6            7\n",
      "69         3        0       7            8>\n",
      "src =  0\n",
      "dst =  3\n",
      "chunk =  2\n",
      "src =  1\n",
      "dst =  0\n",
      "chunk =  5\n",
      "src =  1\n",
      "dst =  2\n",
      "chunk =  6\n",
      "src =  3\n",
      "dst =  0\n",
      "chunk =  8\n",
      "src =  3\n",
      "dst =  6\n",
      "chunk =  4\n",
      "src =  4\n",
      "dst =  3\n",
      "chunk =  5\n",
      "src =  4\n",
      "dst =  5\n",
      "chunk =  0\n",
      "src =  4\n",
      "dst =  7\n",
      "chunk =  2\n",
      "src =  5\n",
      "dst =  8\n",
      "chunk =  2\n",
      "src =  6\n",
      "dst =  7\n",
      "chunk =  1\n",
      "src =  7\n",
      "dst =  8\n",
      "chunk =  0\n",
      "<bound method NDFrame.head of     Timestep  chunkID  source  destination\n",
      "70         4        0       1            2\n",
      "71         4        2       3            6>\n",
      "src =  1\n",
      "dst =  2\n",
      "chunk =  0\n",
      "src =  3\n",
      "dst =  6\n",
      "chunk =  2\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed CSV file\n",
    "df = pd.read_csv('preprocessed_output.csv', header=None) #Header row doesnt exists\n",
    "df.columns = ['Timestep', 'chunkID', 'source', 'destination']\n",
    "\n",
    "# print(df.head) #Print the first 5 rows of the dataframe. Use for debugging\n",
    "\n",
    "# Assuming height and width of the mesh are known\n",
    "height = 3  # Adjust as necessary based on mesh structure\n",
    "width = 3   # Adjust as necessary based on mesh structure\n",
    "\n",
    "def add_all_nodes(G, height, width):\n",
    "    \"\"\"\n",
    "    Adds all nodes to the graph G.\n",
    "\n",
    "    Parameters:\n",
    "    - G (networkx.Graph): The graph to which the nodes will be added.\n",
    "    - height (int): The height of the grid.\n",
    "    - width (int): The width of the grid.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for i in range(height * width):  # Assuming node identifiers are from 0 to height*width-1\n",
    "        G.add_node(i) #in all the mesh, add nodes\n",
    "\n",
    "# Get unique timesteps\n",
    "timesteps = df['Timestep'].unique()\n",
    "\n",
    "graphs = []\n",
    "\n",
    "for timestep in timesteps:\n",
    "    timestep_data = df[df['Timestep'] == timestep] # slice the dataframes into t = 0, 1...N\n",
    "    print(timestep_data.head)\n",
    "    \n",
    "    G = nx.DiGraph() #Create a directed graph\n",
    "    add_all_nodes(G, height, width)  # Add nodes for this timestep\n",
    "    \n",
    "    # Directly use integer identifiers from the CSV\n",
    "    for _, row in timestep_data.iterrows(): #Iterate through the rows of the dataframe\n",
    "        source = row['source'] #Extract the source node\n",
    "        print('src = ',source) \n",
    "        destination = row['destination'] #Extract the destination node\n",
    "        print('dst = ', destination)\n",
    "        chunkID = row['chunkID']    #Extract the chunkID\n",
    "        print('chunk = ', chunkID)\n",
    "        G.add_edge(source, destination, chunkID=chunkID) #Add these nodes as the edge to the graph\n",
    "    \n",
    "    graphs.append(G) #Append this graph to the list of graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Step 1.3 Create data structure node_traffic from graphs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 Thread Blocks:\n",
      "Edge (0, 1) with Thread ID 0:\n",
      "{'timestep': 0, 'chunkID': 0, 'type': 's', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 1, 'chunkID': 3, 'type': 's', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 2, 'chunkID': 6, 'type': 's', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 3, 'chunkID': -1, 'type': '-1', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 4, 'chunkID': -1, 'type': '-1', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "Edge (0, 3) with Thread ID 1:\n",
      "{'timestep': 0, 'chunkID': 0, 'type': 's', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 1, 'chunkID': 1, 'type': 's', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 2, 'chunkID': -1, 'type': '-1', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 3, 'chunkID': 2, 'type': 's', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 4, 'chunkID': -1, 'type': '-1', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "Edge (1, 0) with Thread ID 2:\n",
      "{'timestep': 0, 'chunkID': 1, 'type': 'r', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 1, 'chunkID': 4, 'type': 'r', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 2, 'chunkID': 2, 'type': 'r', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 3, 'chunkID': 5, 'type': 'r', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 4, 'chunkID': -1, 'type': '-1', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "Edge (3, 0) with Thread ID 3:\n",
      "{'timestep': 0, 'chunkID': 3, 'type': 'r', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 1, 'chunkID': 6, 'type': 'r', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 2, 'chunkID': 7, 'type': 'r', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 3, 'chunkID': 8, 'type': 'r', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n",
      "{'timestep': 4, 'chunkID': -1, 'type': '-1', 'deps': -1, 'depsid': -1, 'hasdeps': 0}\n"
     ]
    }
   ],
   "source": [
    "# Normally you would load data from a file like so:\n",
    "# df = pd.read_csv(\"path_to_your_file.csv\")\n",
    "# Load the preprocessed CSV file\n",
    "df = pd.read_csv('preprocessed_output.csv', header=None) #Header row doesnt exists\n",
    "df.columns = ['Timestep', 'chunkID', 'source', 'destination']\n",
    "\n",
    "# Create graphs per timestep\n",
    "graphs = {t: nx.DiGraph() for t in df['Timestep'].unique()}\n",
    "\n",
    "# Populate each graph\n",
    "for _, row in df.iterrows():\n",
    "    graphs[row['Timestep']].add_edge(row['source'], row['destination'], chunkID=row['chunkID'])\n",
    "\n",
    "# Initialize node_traffic from all possible edges in the first graph\n",
    "node_traffic = {}\n",
    "\n",
    "first_graph = graphs[0]  # Assuming the first timestep graph is fully representative\n",
    "for node in first_graph.nodes():\n",
    "    \n",
    "    node_traffic[node] = {}\n",
    "    edge_counter = 0  # Reset counter for each node\n",
    "\n",
    "    # Add thread blocks for all outgoing edges\n",
    "    for target in first_graph.successors(node):\n",
    "        node_traffic[node][(node, target)] = {\n",
    "            'threadID': edge_counter,\n",
    "            'records': [{'timestep': t, 'chunkID': -1, 'type': '-1', 'deps': -1, 'depsid': -1, 'hasdeps': 0} for t in graphs.keys()]\n",
    "        }\n",
    "        edge_counter += 1\n",
    "\n",
    "    # Add thread blocks for all incoming edges if not already added\n",
    "    for source in first_graph.predecessors(node):\n",
    "        if (source, node) not in node_traffic[node]:\n",
    "            node_traffic[node][(source, node)] = {\n",
    "                'threadID': edge_counter,\n",
    "                'records': [{'timestep': t, 'chunkID': -1, 'type': '-1', 'deps': -1, 'depsid': -1, 'hasdeps': 0} for t in graphs.keys()]\n",
    "            }\n",
    "            edge_counter += 1\n",
    "\n",
    "# Populate the node_traffic with actual data from all timestep graphs\n",
    "for t_index, graph in graphs.items():\n",
    "    for source, destination, data in graph.edges(data=True):\n",
    "        node_traffic[source][(source, destination)]['records'][t_index]['chunkID'] = data['chunkID']\n",
    "        node_traffic[source][(source, destination)]['records'][t_index]['type'] = 's'\n",
    "        node_traffic[destination][(source, destination)]['records'][t_index]['chunkID'] = data['chunkID']\n",
    "        node_traffic[destination][(source, destination)]['records'][t_index]['type'] = 'r'\n",
    "\n",
    "# Debug: Print out node_traffic for node 0 to see thread blocks\n",
    "print(\"Node 0 Thread Blocks:\")\n",
    "for edge_key, tb_info in node_traffic[0].items():\n",
    "    print(f\"Edge {edge_key} with Thread ID {tb_info['threadID']}:\")\n",
    "    for record in tb_info['records']:\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_graph = graphs[0]  # Assuming the first timestep graph is fully representative\n",
    "for node in first_graph.nodes():\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(node_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_node_traffic(data, indent=0):\n",
    "    for node, edges in data.items():\n",
    "        print('    ' * indent + str(node) + ':')\n",
    "        if isinstance(edges, dict):\n",
    "            pretty_print_node_traffic(edges, indent + 1)\n",
    "        else:\n",
    "            print('    ' * (indent + 1) + str(edges))\n",
    "\n",
    "pretty_print_node_traffic(node_traffic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.4 Generate XML from data structure node_traffic & dump in XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks/NPU: 1\n",
      "Number of chunks = 9\n"
     ]
    }
   ],
   "source": [
    "def parse_output_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        # Using regular expressions to find the desired pattern\n",
    "        pattern = r'\\[All-Reduce Information\\]\\s*#Chunks/NPU:\\s*(\\d+)'\n",
    "        num_chunks = r'\\[2D Mesh Information\\]\\s*#NPUs:\\s*(\\d+)'\n",
    "        match_chunks_per_npu, match_num_chunks = re.search(pattern, content), re.search(num_chunks, content)\n",
    "        if match_chunks_per_npu and match_num_chunks:\n",
    "            # Extracting the value of #Chunks/NPU\n",
    "            chunks_per_npu, chunks_num = int(match_chunks_per_npu.group(1)), int(match_num_chunks.group(1))\n",
    "            return chunks_per_npu, chunks_num\n",
    "        else:\n",
    "            # If the pattern is not found\n",
    "            return None, None\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"./TACOS_output.txt\" # path to the file (from ./run.sh)\n",
    "chunks_per_npu, num_chunks = parse_output_file(file_path)\n",
    "if chunks_per_npu is not None:\n",
    "    print(\"Chunks/NPU:\", chunks_per_npu)\n",
    "    print(f\"Number of chunks = {num_chunks}\")\n",
    "\n",
    "# Function to generate and save XML in a pretty format\n",
    "def generate_and_save_xml_pretty(node_traffic, filename, chunks_per_npu, num_chunks):\n",
    "\n",
    "    root = ET.Element(\"network\")\n",
    "\n",
    "    # Create <gpu> tags for each node\n",
    "    for node, edges in sorted(node_traffic.items()):\n",
    "        gpu_elem = ET.SubElement(root, \"gpu\", id=str(node), i_chunks=\"0\", o_chunks=str(num_chunks), s_chunks=\"0\")\n",
    "\n",
    "        # Create <tb> tags for each connected edge\n",
    "        for (source, destination), edge_info in edges.items():\n",
    "            tb_elem = ET.SubElement(gpu_elem, \"tb\", id=str(edge_info['threadID']),\n",
    "                                    send=str(destination if edge_info['records'][0]['type'] == 's' else '-1'),\n",
    "                                    recv=str(source if edge_info['records'][0]['type'] == 'r' else '-1'),\n",
    "                                    chan =\"0\")\n",
    "            \n",
    "            # create <step> tags for eeach time step\n",
    "            for record in edge_info['records']:\n",
    "                ET.SubElement(tb_elem, \"step\", s=str(record['timestep']), type=record['type'], srcbuf=\"o\", srcoff=str(record['chunkID']), dstbuf=\"o\", dstoff=str(record['chunkID']), cnt= str(chunks_per_npu), deps=str(record['deps']), depsid=str(record['depsid']), hasdeps=str(record['hasdeps']))\n",
    "\n",
    "    # Convert to string using ElementTree and parse with minidom for pretty printing\n",
    "    rough_string = ET.tostring(root, 'utf-8')\n",
    "    reparsed = xml.dom.minidom.parseString(rough_string)\n",
    "    pretty_xml_as_string = reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "    # Write to file\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(pretty_xml_as_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML file saved as network_flow_pretty.xml\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "filename = 'network_flow_pretty.xml'\n",
    "generate_and_save_xml_pretty(node_traffic, filename, chunks_per_npu, num_chunks)\n",
    "print(f\"XML file saved as {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
